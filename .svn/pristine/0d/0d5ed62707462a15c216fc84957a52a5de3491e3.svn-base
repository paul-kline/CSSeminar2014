[HEADER]
[HEADER:DATASOURCE]
rawFile=FILE_RAW
sourceFile=
sourceFormat=
sourceHeaders=f
[SETUP]
[SETUP:CONFIG]
allowedClasses=integer,string
csvFormat=decpnt|comma
inputHeaders=f
maxClassCount=50
[SETUP:FILENAMES]
FILE_RANDOMIZE=NewDataMomHighValuesPaulMomLittle_random.csv
FILE_EVAL_NORM=NewDataMomHighValuesPaulMomLittle_eval_norm.csv
FILE_EVAL=NewDataMomHighValuesPaulMomLittle_eval.csv
FILE_RAW=NewDataMomHighValuesPaulMomLittle.csv
FILE_ML=NewDataMomHighValuesPaulMomLittle_train.eg
FILE_OUTPUT=NewDataMomHighValuesPaulMomLittle_output.csv
FILE_CLUSTER=NewDataMomHighValuesPaulMomLittle_cluster.csv
FILE_NORMALIZE=NewDataMomHighValuesPaulMomLittle_norm.csv
FILE_TRAINSET=NewDataMomHighValuesPaulMomLittle_train.egb
FILE_TRAIN=NewDataMomHighValuesPaulMomLittle_train.csv
[DATA]
[DATA:CONFIG]
goal=regression
[DATA:STATS]
"name","isclass","iscomplete","isint","isreal","amax","amin","mean","sdev","source"
"field:1",1,1,1,1,28,0,2.5559796438,3.4466650355,""
"field:2",1,1,1,1,3,0,0.3823155216,0.5042619702,""
"field:3",1,1,1,1,3,0,0.1688931298,0.4288861202,""
"field:4",0,1,1,1,76,6,51.4699427481,17.1256410848,""
"field:5",1,1,1,1,8,0,1.4702608142,1.2998604576,""
"field:6",1,1,1,1,4,0,0.8201335878,1.1979341771,""
"field:7",1,1,1,1,1,-1,0,1,""
[DATA:CLASSES]
"field","code","name","count"
"field:1","0","0",2366
"field:1","1","1",745
"field:1","10","10",91
"field:1","11","11",19
"field:1","12","12",92
"field:1","13","13",8
"field:1","14","14",25
"field:1","15","15",21
"field:1","16","16",26
"field:1","17","17",1
"field:1","18","18",7
"field:1","19","19",1
"field:1","2","2",1036
"field:1","20","20",7
"field:1","21","21",6
"field:1","22","22",3
"field:1","24","24",7
"field:1","26","26",2
"field:1","27","27",2
"field:1","28","28",2
"field:1","3","3",394
"field:1","4","4",637
"field:1","5","5",121
"field:1","6","6",318
"field:1","7","7",92
"field:1","8","8",195
"field:1","9","9",64
"field:2","0","0",3937
"field:2","1","1",2302
"field:2","2","2",45
"field:2","3","3",4
"field:3","0","0",5348
"field:3","1","1",833
"field:3","2","2",92
"field:3","3","3",15
"field:5","0","0",1678
"field:5","1","1",1932
"field:5","2","2",1398
"field:5","3","3",772
"field:5","4","4",375
"field:5","5","5",107
"field:5","6","6",18
"field:5","7","7",6
"field:5","8","8",2
"field:6","0","0",3911
"field:6","1","1",609
"field:6","2","2",1012
"field:6","3","3",500
"field:6","4","4",256
"field:7","-1","-1",3144
"field:7","1","1",3144
[NORMALIZE]
[NORMALIZE:CONFIG]
missingValues=DiscardMissing
sourceFile=FILE_TRAIN
targetFile=FILE_NORMALIZE
[NORMALIZE:RANGE]
"name","io","timeSlice","action","high","low"
"field:1","input",0,"equilateral",1,-1
"field:2","input",0,"equilateral",1,-1
"field:3","input",0,"equilateral",1,-1
"field:4","output",0,"range",1,-1
"field:5","input",0,"equilateral",1,-1
"field:6","input",0,"equilateral",1,-1
"field:7","input",0,"oneof",1,-1
[PROCESS]
[PROCESS:CONFIG]
backwardSize=
forwardSize=
sourceFile=
targetFile=
[PROCESS:FIELDS]
"name","command"
[RANDOMIZE]
[RANDOMIZE:CONFIG]
sourceFile=FILE_RAW
targetFile=FILE_RANDOMIZE
[CLUSTER]
[CLUSTER:CONFIG]
clusters=2
sourceFile=FILE_EVAL
targetFile=FILE_CLUSTER
type=kmeans
[BALANCE]
[BALANCE:CONFIG]
balanceField=
countPer=
sourceFile=
targetFile=
[CODE]
[CODE:CONFIG]
embedData=f
targetFile=FILE_CODE
targetLanguage=NOGENERATION
[SEGREGATE]
[SEGREGATE:CONFIG]
sourceFile=FILE_RANDOMIZE
[SEGREGATE:FILES]
"file","percent"
"FILE_TRAIN",75
"FILE_EVAL",25
[GENERATE]
[GENERATE:CONFIG]
sourceFile=FILE_NORMALIZE
targetFile=FILE_TRAINSET
[ML]
[ML:CONFIG]
architecture=?:B->TANH->69:B->TANH->?
evalFile=FILE_EVAL
machineLearningFile=FILE_ML
outputFile=FILE_OUTPUT
query=
trainingFile=FILE_TRAINSET
type=feedforward
[ML:TRAIN]
arguments=
cross=
targetError=0.01
type=rprop
[ML:OPCODES]
"code","count"
[TASKS]
[TASKS:task-cluster]
cluster
[TASKS:task-code]
code
[TASKS:task-create]
create
[TASKS:task-evaluate]
evaluate
[TASKS:task-evaluate-raw]
set ML.CONFIG.evalFile="FILE_EVAL_NORM"
set NORMALIZE.CONFIG.sourceFile="FILE_EVAL"
set NORMALIZE.CONFIG.targetFile="FILE_EVAL_NORM"
normalize
evaluate-raw
[TASKS:task-full]
randomize
segregate
normalize
generate
create
train
evaluate
[TASKS:task-generate]
randomize
segregate
normalize
generate
[TASKS:task-train]
train
